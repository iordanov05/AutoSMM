import logging
from sqlalchemy.orm import Session
from app.models.post import Post
from app.models.group import Group
from app.models.product import Product
from app.models.service import Service
from langchain_chroma import Chroma
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.documents import Document
from app.models.user_group_association import UserGroupAssociation
from app.core.config import CHROMA_DB_PATH, DEEPSEEK_MODEL, OPENROUTER_API_KEY

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM
llm = ChatOpenAI(
    openai_api_key=OPENROUTER_API_KEY,
    base_url="https://openrouter.ai/api/v1",
    model_name=DEEPSEEK_MODEL,
    temperature=0.5,
    max_tokens=3000
)


def save_group_data(db: Session, user_id: int, data: dict):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –≥—Ä—É–ø–ø–µ, –ø–æ—Å—Ç–∞—Ö, —Ç–æ–≤–∞—Ä–∞—Ö –∏ —É—Å–ª—É–≥–∞—Ö –≤ PostgreSQL –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ ChromaDB.
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ vk_group_id
    vk_group_id = data["community"].get("id")
    if not vk_group_id:
        logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω vk_group_id –≤ –¥–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ—Å—Ç–≤–∞!")
        return {"status": "error", "message": "–û—à–∏–±–∫–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç vk_group_id"}
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –≥—Ä—É–ø–ø–∞
    group = db.query(Group).filter(Group.vk_group_id == vk_group_id).first()

    # –ï—Å–ª–∏ –≥—Ä—É–ø–ø–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
    if not group:
        group = Group(
            vk_group_id=vk_group_id,
            name=data["community"]["name"],
            description=data["community"].get("description"),
            subscribers_count=data["community"].get("subscribers_count"),
        )
        db.add(group)
        db.commit()
        db.refresh(group)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å–≤—è–∑—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å —ç—Ç–æ–π –≥—Ä—É–ø–ø–æ–π
    association = db.query(UserGroupAssociation).filter(
        UserGroupAssociation.user_id == user_id,
        UserGroupAssociation.vk_group_id == vk_group_id
    ).first()

    if not association:
        association = UserGroupAssociation(user_id=user_id, vk_group_id=vk_group_id)
        db.add(association)
        db.commit()

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    existing_posts = {p.text for p in db.query(Post).filter(Post.group_id == vk_group_id).all()}
    existing_products = {p.name for p in db.query(Product).filter(Product.group_id == vk_group_id).all()}
    existing_services = {s.name for s in db.query(Service).filter(Service.group_id == vk_group_id).all()}

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ –ø–æ—Å—Ç—ã
    for post in data["posts"]:
        if post["text"] not in existing_posts:
            new_post = Post(
                group_id=vk_group_id,
                text=post["text"],
                likes=post.get("likes", 0),
                comments=post.get("comments", 0),
                reposts=post.get("reposts", 0),
            )
            db.add(new_post)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã
    for product in data["products"]:
        if product["name"] not in existing_products:
            new_product = Product(
                group_id=vk_group_id,
                name=product["name"],
                description=product.get("description"),
                price=product.get("price"),
            )
            db.add(new_product)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–µ —É—Å–ª—É–≥–∏
    for service in data["services"]:
        if service["name"] not in existing_services:
            new_service = Service(
                group_id=vk_group_id,
                name=service["name"],
                description=service.get("description"),
                price=service.get("price"),
            )
            db.add(new_service)

    db.commit()

    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è ChromaDB
    past_posts = db.query(Post).filter(Post.group_id == vk_group_id).all()
    post_styles = "\n\n".join([f"üìù {p.text}" for p in past_posts[-5:]]) if past_posts else "–ù–µ—Ç –∑–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤."

    products_list = db.query(Product).filter(Product.group_id == vk_group_id).all()
    services_list = db.query(Service).filter(Service.group_id == vk_group_id).all()

    doc_description = f"–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã: {group.name}\n–û–ø–∏—Å–∞–Ω–∏–µ: {group.description}\n–ü–æ–¥–ø–∏—Å—á–∏–∫–∏: {group.subscribers_count}"
    doc_products = "–¢–æ–≤–∞—Ä—ã:\n" + ("\n".join([f"{p.name} - {p.description} (–¶–µ–Ω–∞: {p.price})" for p in products_list]) if products_list else "–ù–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤.")
    doc_services = "–£—Å–ª—É–≥–∏:\n" + ("\n".join([f"{s.name} - {s.description} (–¶–µ–Ω–∞: {s.price})" for s in services_list]) if services_list else "–ù–µ—Ç —É—Å–ª—É–≥.")
    doc_posts = "–°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—à–ª—ã—Ö –ø–æ—Å—Ç–æ–≤:\n" + post_styles

    documents = [
        Document(page_content=doc_description, metadata={"vk_group_id": vk_group_id, "type": "description"}),
        Document(page_content=doc_products, metadata={"vk_group_id": vk_group_id, "type": "products"}),
        Document(page_content=doc_services, metadata={"vk_group_id": vk_group_id, "type": "services"}),
        Document(page_content=doc_posts, metadata={"vk_group_id": vk_group_id, "type": "posts"}),
    ]

    # –°–±—Ä–æ—Å –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ ChromaDB
    logger.info("üóëÔ∏è –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è –≥—Ä—É–ø–ø—ã...")
    group_vectorstore = get_group_vectorstore(vk_group_id)
    group_vectorstore.reset_collection()
    group_vectorstore.add_documents(documents)

    full_context = "\n\n".join([doc.page_content for doc in documents])
    logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –æ –≥—Ä—É–ø–ø–µ (vk_group_id={vk_group_id}) —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ ChromaDB!")
    logger.info(f"üìå –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n{full_context}")

    return {
        "status": "success",
        "message": "‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑–µ",
        "group": {
            "id": vk_group_id,
            "name": group.name,
            "description": group.description,
            "subscribers_count": group.subscribers_count
        }
    }

def get_group_vectorstore(vk_group_id: int) -> Chroma:
    """
    –°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä ChromaDB –¥–ª—è —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∏–º–µ–Ω–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–º –Ω–∞ vk_group_id.
    """
    collection_name = f"group_{vk_group_id}"
    vectorstore = Chroma(
        persist_directory=CHROMA_DB_PATH,
        collection_name=collection_name,
        embedding_function=HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    )
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è
        vectorstore.get()
    except ValueError:
        logger.warning(f"‚ö†Ô∏è –ö–æ–ª–ª–µ–∫—Ü–∏—è {collection_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞! –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é...")
        vectorstore.reset_collection()
    return vectorstore

def generate_post_from_context(db: Session, query: str, vk_group_id: int, history: str = "") -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ—Å—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ ChromaDB –¥–ª—è —Å–æ–æ–±—â–µ—Å—Ç–≤–∞.
    –ï—Å–ª–∏ –ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è fallback-–ø–æ–∏—Å–∫ –ø–æ –ø—É—Å—Ç–æ–º—É –∑–∞–ø—Ä–æ—Å—É.
    """
    vectorstore = get_group_vectorstore(vk_group_id)
    # –ò—â–µ–º –±–æ–ª—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, k=4) –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
    
    try:
        results = retriever.invoke(query)
        docs = results if isinstance(results, list) else [results]
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs)} –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è vk_group_id {vk_group_id}: {e}")
        docs = []
    
    if not docs or all(not doc.page_content.strip() for doc in docs):
        logger.warning(f"–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è vk_group_id {vk_group_id} –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback.")
        try:
            fallback_results = retriever.invoke("")
            docs = fallback_results if isinstance(fallback_results, list) else [fallback_results]
            logger.info(f"Fallback –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs)}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ fallback –ø–æ–∏—Å–∫–∞: {e}")
            docs = []
    
    context_texts = "\n\n".join([doc.page_content for doc in docs if doc.page_content.strip()])
    if not context_texts.strip():
        context_texts = "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –≥—Ä—É–ø–ø–µ, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
    
    prompt = f"""
    –¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É. –ù–∞–ø–∏—à–∏ —Ä–µ–∫–ª–∞–º–Ω—ã–π –ø–æ—Å—Ç —Å —É—á–µ—Ç–æ–º –ø—Ä–æ—à–ª—ã—Ö –ø–æ—Å—Ç–æ–≤, –¥–∞–Ω–Ω—ã—Ö –æ –≥—Ä—É–ø–ø–µ –∏ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—â–µ–Ω–∏—è.
    
    üîπ –ò—Å—Ç–æ—Ä–∏—è –æ–±—â–µ–Ω–∏—è:
    {history}
    
    üîπ –î–∞–Ω–Ω—ã–µ –æ –≥—Ä—É–ø–ø–µ:
    {context_texts}
    
    üîπ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç: "{query}"
    
    ‚ùó –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç–∏–ª—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –ø—Ä–æ—à–ª—ã—Ö –ø–æ—Å—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ, —Ö–µ—à—Ç–µ–≥–∏ –∏ —Ç–æ–Ω –æ–±—â–µ–Ω–∏—è.
    ‚ùó –î–æ–±–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã –∏ —É—Å–ª—É–≥–∏ –∏–∑ —Å–ø–∏—Å–∫–∞.
    ‚ùó –ü–∏—à–∏ –ø–æ—Å—Ç –±–µ–∑ –∫–æ–º–∞–Ω–¥ –∏ –ø–æ—è—Å–Ω–µ–Ω–∏–π, —Ç–æ–ª—å–∫–æ —Å–∞–º —Ç–µ–∫—Å—Ç.
    """
    
    logger.info(f"üì¢ [vk_group_id={vk_group_id}] –ü–µ—Ä–µ–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –≤ DeepSeek:\n{prompt}")
    print(prompt)  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
    response = llm.invoke(prompt)
    return response.content.strip()
